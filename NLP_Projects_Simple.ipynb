{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMe9CO0ERxASXLuWS4AAtDY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VenkataramanSuriya/NLP-Projects/blob/main/NLP_Projects_Simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.NO OF WORDS, SENTENCE, SPECL CHAR, DEGITS"
      ],
      "metadata": {
        "id": "Ad4rvSRq5Shn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Text = input(\"Enter a sentence with fullstop :\")\n",
        "\n",
        "words = len(Text.split())\n",
        "print(\"The number of words in given Sentence is :\",words)\n",
        "\n",
        "sentence = Text.count(\".\") + Text.count(\"!\") + Text.count(\"?\")\n",
        "print(\"The number of Sentence :\",sentence)\n",
        "\n",
        "letter = 0\n",
        "for i in Text:\n",
        "  if i.isalpha():\n",
        "    letter = letter+1\n",
        "print(\"The total number of letters :\",letter)\n",
        "\n",
        "spl_char = ['!','@','#','$',\"%\",\"^\",'&',\"*\",'(',')','+','=','{','}','[',']',';',':',\" ' \",' \" ', '<','>','?',',','.','/']\n",
        "splchar_count = 0\n",
        "for i in spl_char:\n",
        "  if i in Text:\n",
        "    splchar_count += Text.count(i)\n",
        "print(\"The number of spl_char in given Sentence is :\",splchar_count,)\n",
        "\n",
        "degit = 0\n",
        "for i in Text:\n",
        "  if i.isdigit():\n",
        "    degit += 1\n",
        "print(\"The total number of letters :\",degit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tqzkh6vO5Rdi",
        "outputId": "2ecec19b-fb67-4089-8ba3-e11428d27d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence with fullstop :Python is an interpreted, object-oriented, high-level programming language with dynamic semantics developed by Guido van Rossum. It was originally released in 1991. Designed to be easy as well as fun, the name \"Python\" is a nod to the British comedy group Monty Python.\n",
            "The number of words in given Sentence is : 43\n",
            "The number of Sentence : 3\n",
            "The total number of letters : 213\n",
            "The number of spl_char in given Sentence is : 6\n",
            "The total number of letters : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter a sentence with a full stop: \")\n",
        "\n",
        "words = len(text.split())\n",
        "print(\"The number of words in the given sentence is:\", words)\n",
        "\n",
        "sentences = text.count(\".\") + text.count(\"!\") + text.count(\"?\")\n",
        "print(\"The number of sentences:\", sentences)\n",
        "\n",
        "letters = 0\n",
        "for char in text:\n",
        "    if char.isalpha():\n",
        "        letters += 1\n",
        "print(\"The total number of letters:\", letters)\n",
        "\n",
        "special_chars = ['!', '@', '#', '$', \"%\", \"^\", '&', \"*\", '(', ')', '+', '=', '{', '}', '[', ']', ';', ':', \"'\", '\"', '<', '>', '?', ',', '.', '/']\n",
        "special_char_count = 0\n",
        "for char in special_chars:\n",
        "    if char in text:\n",
        "        special_char_count += text.count(char)\n",
        "print(\"The number of special characters in the given sentence is:\", special_char_count)\n",
        "\n",
        "digits = 0\n",
        "for char in text:\n",
        "    if char.isdigit():\n",
        "        digits += 1\n",
        "print(\"The total number of digits:\", digits)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KdzyFJ6AOWp",
        "outputId": "c3391dbb-e1a4-46c7-8ae3-03ab569abbf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence with a full stop: Python is an interpreted, object-oriented, high-level programming language with dynamic semantics developed by Guido van Rossum. It was originally released in 1991. Designed to be easy as well as fun, the name \"Python\" is a nod to the British comedy group Monty Python.\n",
            "The number of words in the given sentence is: 43\n",
            "The number of sentences: 3\n",
            "The total number of letters: 213\n",
            "The number of special characters in the given sentence is: 8\n",
            "The total number of digits: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. VALID AND INVALID TOKENS"
      ],
      "metadata": {
        "id": "K8STeYYoBnFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Text = input(\"ENTER THE SENTENCE :\")\n",
        "\n",
        "tokens = Text.split()\n",
        "\n",
        "valid_tokens = 0\n",
        "invalid_tokens = 0\n",
        "\n",
        "for token in tokens:\n",
        "    if token.isalpha():\n",
        "        valid_tokens += 1\n",
        "    else:\n",
        "        invalid_tokens += 1\n",
        "\n",
        "print(\"Valid Tokens:\", valid_tokens)\n",
        "print(\"Invalid Tokens:\", invalid_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8Ma_azWBmiA",
        "outputId": "c4ec1105-5762-4b02-f155-67f9d6d36145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENTER THE SENTENCE :Python is an interpreted, object-oriented, high-level programming language with dynamic semantics developed by Guido van Rossum. It was originally released in 1991. Designed to be easy as well as fun, the name \"Python\" is a nod to the British comedy group Monty Python.\n",
            "Valid Tokens: 35\n",
            "Invalid Tokens: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRPGRAM 3"
      ],
      "metadata": {
        "id": "PEn3WtBQdzcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import PorterStemmer\n",
        "ps=PorterStemmer()\n",
        "word=[\"retrivel\",\"retrived\",\"retrives\"]\n",
        "for v in word:\n",
        "  print(v,\":\",ps.stem(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv7Ku6GVd5A2",
        "outputId": "c5f4bdb9-d78f-409c-f8dc-76940ef6a0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "retrivel : retrivel\n",
            "retrived : retriv\n",
            "retrives : retriv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROGRAM 4"
      ],
      "metadata": {
        "id": "44KBNmcufm-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHm9RJf-fmig",
        "outputId": "dc01d278-0a40-455c-abe2-1534a7485867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import contractions\n",
        "text=(\"i'll be there within 10 min i'd it's\")\n",
        "expanded_words=[]\n",
        "for word in text.split():\n",
        "  expanded_words.append(contractions.fix(text))\n",
        "print(\"original text\",text)\n",
        "print(\"expanded words\",expanded_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZDm8QkLiM54",
        "outputId": "0a5bf978-8164-4b3c-aa19-c12508fbdfd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original text i'll be there within 10 min i'd it's\n",
            "expanded words ['i will be there within 10 min i would it is', 'i will be there within 10 min i would it is', 'i will be there within 10 min i would it is', 'i will be there within 10 min i would it is', 'i will be there within 10 min i would it is', 'i will be there within 10 min i would it is', 'i will be there within 10 min i would it is', 'i will be there within 10 min i would it is']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROGREM 5"
      ],
      "metadata": {
        "id": "3gwgdnyAjdBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT=(\" MASTER THE BLASTER FROM BCA DATA SCIENCE\")\n",
        "NO_WORDS=TEXT.split()\n",
        "tot_no_words=len(NO_WORDS)\n",
        "print(\"the total number of words in given sentence is\",tot_no_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOYWOn6mjlmU",
        "outputId": "9a42097a-07c4-4584-d13f-d4ba96eb8599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the total number of words in given sentence is 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROGRAM = 6 [PRINT IT SENTENCE IN ASSENDING AND DESENDING ORDER]"
      ],
      "metadata": {
        "id": "6Ig1hk3ukS6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "sentence = \"Natural Language Processing is fun and exciting!\"\n",
        "\n",
        "tokens = word_tokenize(sentence)\n",
        "\n",
        "ascending_order = sorted(tokens, key=len)\n",
        "\n",
        "descending_order = sorted(tokens, key=len, reverse=True)\n",
        "\n",
        "print(\"Words in Ascending Order:\", ascending_order)\n",
        "print(\"\\nWords in Descending Order:\", descending_order)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPNO1DgXOVqT",
        "outputId": "0373e497-4971-4426-bf6b-eb3e7a555e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words in Ascending Order: ['!', 'is', 'fun', 'and', 'Natural', 'Language', 'exciting', 'Processing']\n",
            "\n",
            "Words in Descending Order: ['Processing', 'Language', 'exciting', 'Natural', 'fun', 'and', 'is', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text ="
      ],
      "metadata": {
        "id": "Fuw50v2aQPQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROGRAM 7"
      ],
      "metadata": {
        "id": "C5oDlOwWs1bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "text=\"my name is venkat from bca data science /n #mass https://colab.research.google.com/drive/1uD2IbaS653yUbG7FFIDYfAi12io_wu7C#scrollTo=AoZTWF0Ts5S5 ajdhfjg!@#\"\n",
        "toko=word_tokenize(text)\n",
        "invalid_toko=[]\n",
        "mytxt=text.split()\n",
        "for v in mytxt:\n",
        "  if v not in toko:\n",
        "    invalid_toko.append(v)\n",
        "print(\"the valid tokens are\",toko)\n",
        "print(\"the in valid tokens are\",invalid_toko)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoZTWF0Ts5S5",
        "outputId": "5d3ad33e-87ab-44c6-ccb1-c4856ac904c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the valid tokens are ['my', 'name', 'is', 'venkat', 'from', 'bca', 'data', 'science', '/n', '#', 'mass', 'https', ':', '//colab.research.google.com/drive/1uD2IbaS653yUbG7FFIDYfAi12io_wu7C', '#', 'scrollTo=AoZTWF0Ts5S5', 'ajdhfjg', '!', '@', '#']\n",
            "the in valid tokens are ['#mass', 'https://colab.research.google.com/drive/1uD2IbaS653yUbG7FFIDYfAi12io_wu7C#scrollTo=AoZTWF0Ts5S5', 'ajdhfjg!@#']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"my name is venkat from bca data science /n #mass https://colab.research.google.com/drive/1uD2IbaS653yUbG7FFIDYfAi12io_wu7C#scrollTo=AoZTWF0Ts5S5 ajdhfjg!@#\"\n",
        "toko = word_tokenize(text)\n",
        "valid_toko = []\n",
        "invalid_toko = []\n",
        "\n",
        "mytxt = text.split()\n",
        "\n",
        "for v in mytxt:\n",
        "    if v in toko:\n",
        "        valid_toko.append(v)\n",
        "    else:\n",
        "        invalid_toko.append(v)\n",
        "\n",
        "print(\"the valid tokens are\", valid_toko)\n",
        "print(\"the invalid tokens are\", invalid_toko)"
      ],
      "metadata": {
        "id": "wdEUZxcvvKuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d0bce0-5602-4ab1-9c85-137c5277148b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the valid tokens are ['my', 'name', 'is', 'venkat', 'from', 'bca', 'data', 'science', '/n']\n",
            "the invalid tokens are ['#mass', 'https://colab.research.google.com/drive/1uD2IbaS653yUbG7FFIDYfAi12io_wu7C#scrollTo=AoZTWF0Ts5S5', 'ajdhfjg!@#']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. SENTENCE AND WORD TOKENIZER"
      ],
      "metadata": {
        "id": "L2kWm6uczgyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "t1 = input(\"ENTER THE TEXT :\")\n",
        "t2 = input(\"ENTER THE TEXT :\")\n",
        "\n",
        "O1 = word_tokenize(t1)\n",
        "O2 = sent_tokenize(t2)\n",
        "\n",
        "print(O1)\n",
        "print(O2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVqdNLxAx7Su",
        "outputId": "874463ae-e3cd-4ce6-80e7-65c035eacb20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENTER THE TEXT :Python is known for its ease of use, powerful standard library, and dynamic semantics.\n",
            "ENTER THE TEXT :It seems like you've entered the word \"master.\" If you have any specific questions or need assistance with a particular topic or task, please feel free to provide more details, and I'll be happy to help.\n",
            "['Python', 'is', 'known', 'for', 'its', 'ease', 'of', 'use', ',', 'powerful', 'standard', 'library', ',', 'and', 'dynamic', 'semantics', '.']\n",
            "['It seems like you\\'ve entered the word \"master.\"', \"If you have any specific questions or need assistance with a particular topic or task, please feel free to provide more details, and I'll be happy to help.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. NLP WORD_NET LEMMATIZER"
      ],
      "metadata": {
        "id": "vswJf8C6zur2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "words = [\"running\", \"flies\", \"better\", \"rocks\", \"cats\"]\n",
        "\n",
        "for word in words:\n",
        "  lemmatized_words = lemmatizer.lemmatize(word)\n",
        "  print(word,lemmatized_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWkfigIQz1ja",
        "outputId": "c055f69f-73e6-4e73-871d-0c74c070a0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running running\n",
            "flies fly\n",
            "better better\n",
            "rocks rock\n",
            "cats cat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.python program for ngrams"
      ],
      "metadata": {
        "id": "hkGJSwKu1oPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import ngrams\n",
        "\n",
        "text = 'Python is known for its ease of use, powerful standard library, and dynamic semantics.'\n",
        "\n",
        "n=6\n",
        "unigram = ngrams(text.split(),n)\n",
        "for g in unigram:\n",
        "  print(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DfH8hI_1gZ7",
        "outputId": "c539d33e-89a2-45e4-8195-a962d2ad8be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Python', 'is', 'known', 'for', 'its', 'ease')\n",
            "('is', 'known', 'for', 'its', 'ease', 'of')\n",
            "('known', 'for', 'its', 'ease', 'of', 'use,')\n",
            "('for', 'its', 'ease', 'of', 'use,', 'powerful')\n",
            "('its', 'ease', 'of', 'use,', 'powerful', 'standard')\n",
            "('ease', 'of', 'use,', 'powerful', 'standard', 'library,')\n",
            "('of', 'use,', 'powerful', 'standard', 'library,', 'and')\n",
            "('use,', 'powerful', 'standard', 'library,', 'and', 'dynamic')\n",
            "('powerful', 'standard', 'library,', 'and', 'dynamic', 'semantics.')\n"
          ]
        }
      ]
    }
  ]
}